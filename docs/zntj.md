# 智能推荐系统

智能推荐，即基于大数据的个性化推荐系统最终的目标就是让一个普通访问平台的用户，在三类场景下，提升购买转化率。

- 在进入平台页面时，系统能够根据用户日常的行为偏好和习惯，把用户心里想要购买的商品，在用户还没有发生点击行为时，由系统自动推荐到用户访问的页面，提升平台用户购买转化率；

- 在用户还没有访问平台时，企业通过与用户日常浏览互联网行为轨迹的平台进行联盟合作，在联盟平台推送用户希望购买的商品广告和链接，刺激和引导用户点击购买；

- 在用户处于离线状态时，通过信息和邮件的方式，根据用户平常的购买频次和周期，在特定的时间推送到用户的手机和电脑。

想要实现前端给用户以千人千面的推荐，后端就需要建立复杂的用户全网行为数据采集、存储加工、数据建模和用户画像过程，单纯采集互联网电商平台数据，仅能达到个性化推荐效果的40%左右，如果要提升个性化推荐的效果，就必须覆盖用户全网行为轨迹，甚至用户线下的行为轨迹，这就形成了以互联网电商平台为核心的生态系统，这也是阿里、腾讯为什么要控股或收购各行业企业的原因之一。

它通常是由三个部分构成：第一部分是建立平台用户行为的召回模型；第二部分是召回模型匹配算法；第三部分是平台针对匹配模型推荐结果的排序算法。

`建立平台用户行为的召回模型`

维度基于用户历史行为数据召回、用户偏好召回和用户地域召回来实现，其中，

- 用户历史行为数据召回基于用户历史浏览、点击、购买、评论、分享、收藏、关注等触点，分类推荐在线相关、在线相似、离线相关、离线相似行为；

- 用户偏好召回是基于用户归类画像与平台多屏互通融合；

- 用户地域召回是基于用户地域的网格化来实现地域行为推荐算法；

`召回模型匹配算法`

利用高斯逻辑回归及多维算法来得出与用户召回行为的匹配商品及广告信息；

`平台针对匹配模型推荐结果的排序算法`

基于用户交互日志通过模型训练特征权重，采用排序算法来实现自动匹配个性化推荐。

在系统实现技术架构上，为支撑个性化推荐系统平均至少每周进行算法迭代，采用HBase、Spark及MapReduce等系统架构，在个性化推荐系统优化升级中，与DNN融合的速度越来越快。

## 用户行为数据采集

在需要采集的互联网平台页面上进行埋点，在页面放置“蜘蛛”探针对业务系统所有的访问和操作日志进行采集，同时从数据库中提取业务数据，存储在数据仓库。

数据分析维度体系如下图所示：

![image](/http://p3.pstatp.com/large/3090006c9a45958e303)

同时，要使系统采集的数据指标能够支持平台前端的个性化行为分析，必须围绕用户为主线来进行画像设计，在初期可视化报表成果基础上，将统计出来的不同规模数据，细分定位到每个用户，使每个数据都有一个用户归属。将分散无序的统计数据，在依据用户来衔接起来，在现有产品界面上，每个统计数据都增加一个标签，点击标签，可以展示对应每个用户的行为数据，同时可以链接到其他统计数据页面。

由此可以推导出，以用户为主线来建立数据采集指标维度：

- 用户身份信息维度：性别，年龄，星座，居住城市，活跃区域，证件信息，学历，收入，健康等。

- 用户社会生活信息维度：行业，职业，是否有孩子，孩子年龄，车辆，住房性质，通信情况，流量使用情况……

- 用户资产信息维度：是否有网购行为，风险敏感度，价格敏感度，品牌敏感度，收益敏感度，产品偏好，渠道偏好……

- 用户行为偏好信息维度：用户参与的活动，参与的讨论，收藏的产品，购买过的商品，推荐过的产品，评论过的产品……

- 用户购物偏好：品类偏好，产品偏好，购物频次，浏览偏好，营销广告喜好，购物时间偏好，单次购物最高金额……

- 用户价值

- 用户反馈

- 用户忠诚度

等等。

如下图所示：

![image](/http://p2.pstatp.com/large/3030003198213c1fde3)

通过建立的用户行为数据采集指标体系后，将其再细分到数据属性值，进入这个环节，就需要依赖各种建立的数据模型或函数算法，来对平台用户进行特征提取分析，计算出用户对应的画像数据值，这才是用户画像过程中最为关键的环节。

`例子`

如果一个用户访问浏览一个电商平台，注册时没有填写性别，平台如何通过用户产生的访问浏览行为，来计算出用户的性别。绝大多数电商平台都是通过用户的浏览商品，为其推荐相同或相关的商品或相关商品类目商品，用户浏览了连衣裙，并不能说明用户就是女性，因此，要能够更加准确的向用户推荐个性化商品，就必须通过数据特征提取，函数算法来计算出用户的性别。如下图的流程：

![image](/http://p2.pstatp.com/large/2fe000f02d638762c18)

## 数据存储加工

用户行为数据采集后，需要存储在数据仓库，对采集的原始数据进行ETL加工处理，首先需要处理掉存储的无效重复数据，对于用户行为没有影响或重复数据，对非结构化数据和半结构化数据进行结构化处理，并对数据进行补缺、替换、数据合并、数据拆分、数据加载和异常处理。（这个环节更多是技术程序处理）

一般流程如下：

- 采集服务器组负责将采集到的日志信息生成文件，落地到存储设备；

- ETL服务器负责将日志文件和结构化数据导入Hadoop分析集群，并将分析结果导出到Oracle数据库；

- 数据解析服务器负责连接Hadoop环境，完成数据分析所需的各项计算；

- Hadoop和Hive提供数据分布式存储和计算的基础框架；

- 调度实现以上数据导入、分析和结果导出的所有任务的统一调度；

- 数据展示服务器负责数据分析结果的多种形式展现。

## 数据建模及用户特征提取、画像

对于加工处理后的用户行为数据，利用开源的机器学习分类器包，调用封装好的各种数据函数，神经网络、支持向量机、贝叶斯等对数据进行聚类、分类和预测，根据第一步设计的用户画像标签体系，对访问平台的用户计算行为特征值，用户特征提取并不是针对所有的标签维度，对于优先关键标签，如果从用户数据库查询不到特征值，就需要调用R函数对其进行计算，最终得出每个标签维度的特征值，依据特征属性值，就可以对用户进行画像处理。

![image](/http://p2.pstatp.com/large/3090006c9a8893103f3)

按照用户属性和行为特征对全部用户进行聚类和精细化的客户群细分，将用户行为相同或相似的用户归类到一个子库，这样就可以将电商平台所有的用户划分为N个不同子库，每个子库用户拥有相同或相似的行为特征，到这一步，电商平台就可以按照不同子库行为对其进行个性化智能推荐。

![image](/http://p2.pstatp.com/large/304000576d7e9ed8e0e)

目前国内主流电商平台，在进行个性化智能推荐系统升级过程，都在逐步向DNN渗透和扩展，也是未来个性化智能推荐必经之路。在现有用户画像、用户属性打标签、客户和营销规则配置推送、同类型用户特性归集分库模型基础上，未来将逐步扩展机器深度学习功能，通过系统自动搜集分析前端用户实时变化数据，依据建设的机器深度学习函数模型，自动计算匹配用户需求的函数参数和对应规则，推荐系统根据计算出的规则模型，实时自动推送高度匹配的营销活动和内容信息。

![image](/http://p3.pstatp.com/large/3090006c9abd3bd31b9)

归根结底，无论是做个性化智能推荐还是大数据进行研究探索，最终都是要达到让系统更加智能的准确识别和推送用户心理想要的产品或内容，也就是互联网平台与用户前端交互的效果，使系统具有人类大脑的效果，更加智能、甚至学会思考。

以上文章来源为[智能推荐系统介绍](http://toutiao.com/i6259154582471967234/?tt_from=mobile_qq&utm_campaign=client_share&app=news_article&utm_source=mobile_qq&iid=3636877074&utm_medium=toutiao_android)

## 显式隐式反馈数据

用户行为和关系数据能真实的反映每个用户的偏好和习惯。采集这些基础数据，并做好清洗和预处理，是整个推荐系统的基石。

用户行为数据，又可以细分为两部分：

`显式反馈数据（explicitfeedbacks）`

显式反馈是指能够明确表达出用户好恶的行为数据，例如用户对某商品的购买、收藏、评分等数据。

`隐式反馈数据（implicitfeedbacks）`

隐式反馈是指无法直接体现用户偏好的行为，例如用户在网站中的点击、浏览、停留、跳转、关闭等行为。

通过挖掘显式反馈数据能够明确把握用户的偏好，但是在很多应用中，显式反馈数据通常很稀少，导致对用户偏好的挖掘无法深入。这个问题在一些刚上线的应用、或者偏冷门的物品或用户身上尤其明显。在这种情况下，用户的隐式反馈数据就显得尤为重要。

例如，在2006-2008年间进行的国际著名推荐竞赛NetflixPrize中，冠军队成员YehudaKoren发现将用户租用影片的记录，转换为特征向量注入奇异值分解算法（SVD）用于影响用户兴趣向量，能够很好的提高推荐准确率。

同时，基础数据的预处理对推荐效果的提升也非常有帮助。

例如，2012年的ACMKDD-Cup（国际数据挖掘竞赛），训练样本中，负样本的数量居然达到了总样本数量的92.82%，但是通过仔细分析这些负样本，发现其中有大量样本存在噪音，通过一系列的Session分析和筛选方法，从中保留了11.2%的样本进行后续推荐挖掘，不仅成功提高了推荐精度，而且大大减少了运算量。所以充分利用各类显式和隐式数据，并做好数据的预处理，保证输入数据的质量，是第一个关键点。

## 推荐需要重视时间因素

用户的行为是存在很强的时间规律的。例如，人们中午会吃饭、周末会休假、过年会回家团圆等等。用户在各个应用中的行为也同样有规律可以挖掘，用好时间这个特征，在很多推荐场景下，会对推荐效果的提升有很大的帮助。

用户行为日志中，行为发生的时间戳（timestamp）通常都会被记录。这个时间戳能从user和item两方面来进行分析。

`user`

从user的角度来看，user的兴趣往往会随着时间不断变化，几年前的兴趣和当前的兴趣可能是不同的，另一方面，user的行为也存在一定的规律，例如工作日的行为是类似的，而在周末里user的行为也会发生变化。甚至在同一天中，白天和晚上的user行为和偏好也会有各种不同的规律。

`item`

从item的角度来看，流行度随着时间会有规律性的波动。通过持续挖掘user和item之间的行为在一段时间的记录，往往能够发掘出这种规律，并进而用于指导我们预测user在后续某个时刻的行为，提高推荐的准确率。

时间因素的一些常见处理方案包括：

- 在协同过滤计算user或者item相似度的公式中，增加时间因子，发挥相近时间的作用；

- 将时间离散映射到自然月、周、日、小时等时间片中，并分别进行统计计算，并进而将累积的数据用于特定的回归模型（Regressionmodels）中，指导结果预测；

- 将时间作为线性连续变量，用于训练模型参数等。

## 特定推荐场景需要使用地域特征

有一些推荐场景是和用户所处地域密切相关的，尤其对一些LBS、O2O的应用来说，一旦离开地域这个特征，那么智能推荐的效果根本就无从谈起。例如当需要推荐一个餐馆时，如果不考虑用户当前所在的位置，那么即使某餐馆和当前用户的口味匹配度非常高，但远在天边，这个推荐也是毫无价值的。

目前推荐系统在地域特征的使用还停留在较为原始的状态，通常需要让用户手工筛选推荐结果所在的区域（如省、市、区、县等），或者指定若干半径范围内的结果。这种方式不仅操作繁琐，而且缺乏对地域信息的细致分析。例如地点A和B的地图直线距离虽然较远，但两点间有地铁直接往返，而另一地点C虽然地图直线距离A很近，但两点间需要绕行交通不便。另外从用户角度来说，每天活动的地域总是存在规律的，例如工作日白天，往往活动区域在工作地点附近，夜晚的时间会在家附近等。

在基于地理位置信息的应用中，需要更聪明的挖掘用户对地域的偏好（而且这种偏好往往和时间紧密联系），例如在基于用户的协同过滤中，将类似地域用户活跃用户的行为，作为推荐的依据，即认为活动地域相似的用户，可能存在一定相同的偏好。或者使用基于物品的协同过滤思想，在计算item之间相似度时引入地域特征。在LatentFactorModel中，将用户的活动地域作为隐式反馈来作用于用户特征向量等，都是可行的方案。

手机是进行基于地域信息推荐的最好载体，随着移动互联网应用越来越普及，期待未来有更多基于地域信息的推荐产品的问世。

## SNS关系的使用

社交网络近年来得到了突飞猛进的发展，用户不再是单纯的内容接收者，而是能够主动的建立用户之间的关系。这些关系，可以划分为显式关系（explicitrelations）和隐式关系（implicitrelations）。

`显式关系`

指的是用户已明确建立的相关关系，例如在微博中关注/被关注某人，或者在社区中加为好友等。

`隐式关系`

指的是用户之间存在一些互动行为，但这些行为不能明确指示用户间的关系。例如用户在微博中点击、评论、转发另一个用户的帖子，或者在网络游戏世界与另个玩家交谈或者PK等。

隐式关系虽然并不如显式关系那样明确，但比显式关系要丰富的多。所以在一些对推荐精度要求很高的应用场景下，显式关系需要发挥主要作用；而对一些需要提高推荐召回率和推荐结果多样性的场景下，尤其是当显式关系面临数据稀疏性的问题时（注：这个问题在推荐应用中普遍存在），充分利用隐式关系能起到非常好的效果。

以今年的KDD-Cup竞赛为例，在腾讯微博的好友推荐系统上，我们通过在SVD++模型中增加隐式关系，处理数据稀疏性的问题，能够将推荐准确率提升5.5%

此外，移动互联网的普及，让SNS关系使用起来更加便捷，而且加上地域信息，产生了像微信这样新颖的移动应用，而SNS关系和地域特征的结合使用，一定会让推荐系统也产生出更受欢迎的结果。

## 大数据挖掘和性能优化

大数据挖掘是近年来的研究热点，得益于分布式计算技术的广泛使用，系统吞吐的数据规模越来越大，离线数据挖掘的能力也越来越强，处理大量用户行为数据变得越来越便捷。但在推荐挖掘中，系统能够提供的运算能力和实际的运算需求之间，始终存在矛盾，所以如果有效合理的分配运算资源十分重要。这里需要在挖掘深度上进行合理的分配。对重点的用户或者item，可以分配更多的资源，进行更深入的挖掘。对基础数据也是如此，高质量的数据可以用于更详细的分析，而低价值的数据可能只需要简化处理流程。

后端的离线系统往往还需要定期更新模型，这里模型的全量或增量更新方式也是一个值得关注的点。以用户模型为例，并非所有用户的个性化模型都需要频繁更新，活跃的、高贡献值的用户，应该需要更频繁的予以更新。对item也类似，热门item和冷门item更新技术的周期可以不同。

在大数据推荐系统的性能优化方面，还有一些常用的技巧，例如倒排索引的使用，cache机制的充分运用等。

## 明确优化目标和评估手段

开发一个初步可用的推荐系统并不难，难的是如何在原有推荐效果的基础上精益求精，更进一步。优化目标和评估手段的确定是解决这个问题的关键所在。首先需要确定系统的优化目标。例如有些推荐系统追求推荐结果的点击率；有些则还考虑点击后的实际转化或成交效果；有些推荐场景更关注推荐结果的新颖性，即希望更多的将本站新收录的物品展现给用户；另一些则更重视结果的多样性。

在推荐系统的目标明确后，随之而来的问题是，如何量化的评价这些推荐目标？传统的评分预测问题通常使用均方根误差（RMSE）或者平均绝对误差（MAE）等计算方法。但在实际应用中Top-N推荐更为常见，这种场景下NDCG(NormalizedDiscountedCumulativeGain)或MAP（MeanAveragePrecision）是普遍使用的衡量方法。

由于推荐系统经常借鉴相关领域的一些技术，如广告学或搜索系统，因此计算广告学中的pCTR或者搜索系统的Precision-Recall曲线等也经常用于评估推荐效果的优劣。有些系统甚至直接将推荐系统转化为一个机器学习问题，评估手段也随之转化为对应问题的方法。

实际系统中，往往是多个指标（点击率、准确率、覆盖率、多样性、新颖性等）共同作用，并且按照产品的实际需求，加权折衷后进行结果评测。测试方法也有线上A/BTesting以及人工评测等。无论采用何种方法，一个成熟的推荐系统一定要建立在明确的优化目标和评测系统之上，它们像一把尺子，丈量着推荐系统每次前进的脚步。

以上文章来源为[关于智能推荐的6个小经验，你值得拥有！](https://www.jianshu.com/p/a03abb36e09c)
